import logging
import os
import uuid
import shutil
import time
from fastapi import FastAPI, HTTPException, status, UploadFile, File, Form, BackgroundTasks
from contextlib import asynccontextmanager

from schemas import ProcessInitiatedResponse
from config import TEMP_UPLOAD_DIR, ULTRALYTICS_OUTPUT_DIR, DEVICE
from yolo_processor import yolo_video_processor
from telegram_sender import send_message, send_video

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(name)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)
logger = logging.getLogger(__name__)


async def background_video_processing_task(
    temp_input_video_path: str, 
    chat_id: int, 
    original_status_message_id: int
):
    task_start_time = time.time()
    logger.info(f"–ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ {temp_input_video_path} –¥–ª—è chat_id {chat_id}")
    

    processed_video_path: str | None = None
    experiment_output_dir: str | None = None

    try:
        processed_video_path, pedestrian_count, trajectories, boxes_per_frame = (yolo_video_processor.process_and_track_video(temp_input_video_path))
        final_video_path = processed_video_path

        caption = (
            f"‚úÖ –í–∏–¥–µ–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ!\n"
            f"üö∂‚Äç‚ôÇÔ∏è –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–µ—à–µ—Ö–æ–¥–æ–≤: {pedestrian_count}\n"
        )

        if trajectories and boxes_per_frame:
            try:
                clustered_video_path, cluster_counts = yolo_video_processor.clusters_visualize(
                    input_video_path=temp_input_video_path,
                    trajectories=trajectories,
                    boxes_per_frame=boxes_per_frame,
                    output_path=os.path.dirname(processed_video_path)
                )
                if clustered_video_path:
                    final_video_path = clustered_video_path

                noise_tracks = cluster_counts.get(-1, 0)
                total_tracks = sum(cluster_counts.values())
                if total_tracks > 0:
                    noise_ratio = (noise_tracks / total_tracks) * 100
                else:
                    noise_ratio = 0.0

                clusters_info = "\n".join(
                    f"–ö–ª–∞—Å—Ç–µ—Ä {cid+1}: —á–∏—Å–ª–æ –ø–µ—à–µ—Ö–æ–¥–æ–≤¬†{count}"
                    for cid, count in sorted(cluster_counts.items())
                    if cid != -1
                )

                if clusters_info:
                    caption += f"{clusters_info}\n"
                caption += f"–ü–µ—à–µ—Ö–æ–¥–æ–≤, –Ω–µ –ø–æ–ø–∞–≤—à–∏—Ö –≤ –∫–ª–∞—Å—Ç–µ—Ä—ã:¬†{noise_tracks} ({noise_ratio:.1f}% –æ—Ç¬†–æ–±—â–µ–≥–æ —á–∏—Å–ª–∞)\n"

            except ValueError as ve:
                logger.warning(f"–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞: {ve}")
                caption += "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–¥–µ–ª–∏—Ç—å –∫–ª–∞—Å—Ç–µ—Ä—ã –¥–≤–∏–∂–µ–Ω–∏—è.\n"
                final_video_path = processed_video_path

        task_duration = time.time() - task_start_time
        logger.info(f"–í–∏–¥–µ–æ {temp_input_video_path} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞ {task_duration:.2f} —Å–µ–∫.")
        caption += f"‚è± –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ: {task_duration:.1f} —Å–µ–∫."

        send_success = await send_video(chat_id, final_video_path, caption)
        if not send_success:
            await send_message(chat_id, "–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –≤–∏–¥–µ–æ. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –±–æ—Ç–∞.")

    except Exception as e:
        task_duration = time.time() - task_start_time
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∏–¥–µ–æ {temp_input_video_path} –∑–∞ {task_duration:.2f} —Å–µ–∫: {e}", exc_info=True)
        await send_message(chat_id, f"‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞ –≤–æ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.", message_id_to_edit=original_status_message_id)
    
    finally:
        if os.path.exists(temp_input_video_path):
            try:
                os.remove(temp_input_video_path)
                logger.info(f"–í—Ä–µ–º–µ–Ω–Ω—ã–π –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª {temp_input_video_path} —É–¥–∞–ª–µ–Ω.")
            except Exception as e_clean:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ {temp_input_video_path}: {e_clean}")
        
        if processed_video_path:
            experiment_output_dir = os.path.dirname(processed_video_path)
            if experiment_output_dir and os.path.exists(experiment_output_dir) and ULTRALYTICS_OUTPUT_DIR in experiment_output_dir: # –î–≤–æ–π–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
                try:
                    shutil.rmtree(experiment_output_dir)
                    logger.info(f"–ü–∞–ø–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ Ultralytics {experiment_output_dir} —É–¥–∞–ª–µ–Ω–∞.")
                except Exception as e_clean_exp:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –ø–∞–ø–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ Ultralytics {experiment_output_dir}: {e_clean_exp}")


@asynccontextmanager
async def lifespan(app: FastAPI):
    logger.info("Backend –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è...")
    logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è PyTorch: {DEVICE}")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ YoloVideoProcessor
    if yolo_video_processor is not None:
        logger.info("YoloVideoProcessor —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")
    else:
        raise RuntimeError("YoloVideoProcessor failed to initialize. Check model path and CUDA setup.")
    yield


app = FastAPI(
    title="Backend API",
    lifespan=lifespan
)

@app.post("/api/v1/video/process", response_model=ProcessInitiatedResponse, status_code=status.HTTP_202_ACCEPTED)
async def process_video_endpoint(
    background_tasks: BackgroundTasks,
    video_file: UploadFile = File(...),
    chat_id: int = Form(...),
    message_id: int = Form(...)
):
    if not video_file.content_type == "video/mp4":
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="–ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞. –¢—Ä–µ–±—É–µ—Ç—Å—è MP4.")

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É
    file_extension = ".mp4" # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ, —Ç.–∫. –º—ã –ø—Ä–æ–≤–µ—Ä—è–µ–º content_type
    temp_input_filename = f"{uuid.uuid4()}{file_extension}"
    temp_input_video_path = os.path.join(TEMP_UPLOAD_DIR, temp_input_filename)

    try:
        with open(temp_input_video_path, "wb") as buffer:
            shutil.copyfileobj(video_file.file, buffer)
        logger.info(f"–í–∏–¥–µ–æ—Ñ–∞–π–ª '{video_file.filename}' —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤—Ä–µ–º–µ–Ω–Ω–æ –∫–∞–∫ '{temp_input_video_path}' –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.")
    except Exception as e:
        logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π –≤–∏–¥–µ–æ—Ñ–∞–π–ª '{video_file.filename}': {e}", exc_info=True)
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤–∏–¥–µ–æ—Ñ–∞–π–ª–∞ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ.")
    finally:
        await video_file.close()

    background_tasks.add_task(
        background_video_processing_task, 
        temp_input_video_path, 
        chat_id, 
        message_id
    )
    
    logger.info(f"–§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ '{temp_input_video_path}' (chat_id: {chat_id}) –¥–æ–±–∞–≤–ª–µ–Ω–∞.")
    
    return ProcessInitiatedResponse(
        message=f"–í–∏–¥–µ–æ '{video_file.filename or '—Ñ–∞–π–ª'}' –ø—Ä–∏–Ω—è—Ç–æ –∏ –ø–æ—Å—Ç–∞–≤–ª–µ–Ω–æ –≤ –æ—á–µ—Ä–µ–¥—å –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É. –í—ã –ø–æ–ª—É—á–∏—Ç–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏."
    )

@app.get("/health")
async def health_check():
    yolo_status = "–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω" if yolo_video_processor and yolo_video_processor.model else "–ù–ï –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω"
    return {
        "status": "healthy", 
        "pytorch_device": str(DEVICE),
        "yolo_model_status": yolo_status
        }